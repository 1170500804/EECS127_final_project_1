{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVYA302cLyfP"
   },
   "source": [
    "# Provable Robustness for Deep Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LbEBZGKLyfZ"
   },
   "source": [
    "In this notebook, we will implement the robustness certificate that we derived in the PDF. That is, we will first define and train a three-layer neural classifier; then, we will calculate its dual, and using this, check whether the classifier is dual at given input points.\n",
    "\n",
    "**Your task is to fill in any sections labeled TODO in the code and answer the bolded questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSv1e7M36T5D"
   },
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJMgQYklLyfd"
   },
   "source": [
    "We are using torch here; for our purposes, we can think of torch as essentially numpy with GPU support and and automatic differentiation. That is, for any function we compute, torch automatically keeps track of the function's gradient with respect to inputs; this will make gradient descent much easier to implement. \n",
    "\n",
    "The primary object you will need to manipulate here is `torch.Tensor`, which can be thought of as equivalent to  `np.array`. Indexing, splicing, multiplication, etc. will work like you would expect them to in numpy.\n",
    "\n",
    "Also, most of the numpy functions you are used to are present in torch, with the same name. E.g:\n",
    "* `np.max(input, axis)` --> `torch.max(input, dim)` (Note that `torch.max` actually returns a tuple of the max and argmax).\n",
    "* `np.zeros` --> `torch.zeros`\n",
    "* `np.eye` --> `torch.eye`\n",
    "* `np.linalg.norm(x, ord, axis)` --> `torch.norm(input, p, dim)`\n",
    "\n",
    "For more information, refer to the [torch documentation](https://pytorch.org/docs/stable/torch.html) or the [torch tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3ChNfnaLBbw"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PczgocJtLBb0"
   },
   "source": [
    "Here, we import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3oepvCSLyfi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPbnELbsLBcM"
   },
   "source": [
    "This line tells torch to use the GPU if available, and otherwise the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hBpT1WebQ394",
    "outputId": "1c3a8f03-da0b-47be-fc96-be1425dac763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awgBbuiRLyf0"
   },
   "source": [
    "Here, we load in the MNIST dataset. The inputs are $28\\times 28$ images of handwritten digits, while the labels are the corresponding digit. Note that we split the data between a training set and a test set. In order to have an unbiased estimate of the classifier's performance, we must train the model only on the training set (**never the test set**), then test its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q58IyfpGLyf4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4iXn51ILygD"
   },
   "source": [
    "This is a utility function to visualize torch Tensors as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EkoFimALygG"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    '''\n",
    "    Visualizes IMG.\n",
    "    IMG should be a 2D torch Tensor.\n",
    "    '''\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iu56FwY-LBc9"
   },
   "source": [
    "## Primal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAc2QEcALygQ"
   },
   "source": [
    "Here, we define the neural classifier we will be using. Note that the network comprises three layers. The first layer has dimension $28^2$ since this is the size of the input image. (The original inputs are square images, but we flatten them into a $28^2\\times 1$ vector in order to feed them into the network.) The output layer has dimension $10$, since there are ten possible output classes (the digits 0-9). The hidden layer has dimension $256$. (There isn't as much science behind choosing the dimensionality of input layers; we choose $256$ because it is a round number, and is hopefully enough to the neccesary encode information about the input image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-joaa2DLygU"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=28*28, out_features = 256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features = 10)\n",
    "        self.layers = [self.fc1, self.fc2]\n",
    "\n",
    "  # define forward function\n",
    "    def forward(self, t):\n",
    "        '''\n",
    "        On input T, performs a affine transformation, then\n",
    "        a ReLU, then another affine transformation.\n",
    "        '''\n",
    "        self.z = []\n",
    "        t = t.reshape(-1, 28*28)\n",
    "        t = self.fc1(t)\n",
    "        self.z.append(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        self.z.append(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTue7LMGLygd"
   },
   "source": [
    "Here is the training code, which uses Adam, a variant of gradient descent. The actual optimization machinery is all abstracted away behind the torch library; all the work is being done by the `optimizer.step()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zdMiOXDLygf"
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, trainloader, lr=0.001):\n",
    "    '''\n",
    "    Uses the Adam optimization algorithm to train \n",
    "    the classifier NET on training data from TRAINLOADER,\n",
    "    on loss function CRITERION, with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmx06HSLLyhh"
   },
   "source": [
    "We can now train the net on the training data, using cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "id": "W8pmvL6tLyhj",
    "outputId": "4a61e98c-162a-4b4d-f39a-2eaa82a9eeb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iter: 0 Loss 2.289048194885254\n",
      "Epoch 0 Iter: 500 Loss 0.12315428256988525\n",
      "Epoch 0 Iter: 1000 Loss 0.27355486154556274\n",
      "Epoch 0 Iter: 1500 Loss 0.19797652959823608\n",
      "Epoch 0 Iter: 2000 Loss 0.11937451362609863\n",
      "Epoch 0 Iter: 2500 Loss 1.3180737495422363\n",
      "Epoch 0 Iter: 3000 Loss 0.5733668804168701\n",
      "Epoch 0 Iter: 3500 Loss 0.022939205169677734\n",
      "Epoch 0 Iter: 4000 Loss 0.10624265670776367\n",
      "Epoch 0 Iter: 4500 Loss 0.32269287109375\n",
      "Epoch 0 Iter: 5000 Loss 0.00554811954498291\n",
      "Epoch 0 Iter: 5500 Loss 0.20479059219360352\n",
      "Epoch 0 Iter: 6000 Loss 0.022185683250427246\n",
      "Epoch 0 Iter: 6500 Loss 0.041847407817840576\n",
      "Epoch 0 Iter: 7000 Loss 0.06954514980316162\n",
      "Epoch 0 Iter: 7500 Loss 0.00995945930480957\n",
      "Epoch 0 Iter: 8000 Loss 0.09848421812057495\n",
      "Epoch 0 Iter: 8500 Loss 0.00448453426361084\n",
      "Epoch 0 Iter: 9000 Loss 0.008963227272033691\n",
      "Epoch 0 Iter: 9500 Loss 0.02578192949295044\n",
      "Epoch 0 Iter: 10000 Loss 0.004914045333862305\n",
      "Epoch 0 Iter: 10500 Loss 1.4364607334136963\n",
      "Epoch 0 Iter: 11000 Loss 0.0404353141784668\n",
      "Epoch 0 Iter: 11500 Loss 0.003002762794494629\n",
      "Epoch 0 Iter: 12000 Loss 0.7548469305038452\n",
      "Epoch 0 Iter: 12500 Loss 0.002043008804321289\n",
      "Epoch 0 Iter: 13000 Loss 0.09219479560852051\n",
      "Epoch 0 Iter: 13500 Loss 0.0067255496978759766\n",
      "Epoch 0 Iter: 14000 Loss 0.409676194190979\n",
      "Epoch 0 Iter: 14500 Loss 0.008940458297729492\n",
      "Epoch 1 Iter: 0 Loss 0.13097059726715088\n",
      "Epoch 1 Iter: 500 Loss 0.08075040578842163\n",
      "Epoch 1 Iter: 1000 Loss 0.0789598822593689\n",
      "Epoch 1 Iter: 1500 Loss 0.07522368431091309\n",
      "Epoch 1 Iter: 2000 Loss 0.028467237949371338\n",
      "Epoch 1 Iter: 2500 Loss 0.0059441328048706055\n",
      "Epoch 1 Iter: 3000 Loss 0.018410921096801758\n",
      "Epoch 1 Iter: 3500 Loss 0.05136960744857788\n",
      "Epoch 1 Iter: 4000 Loss 0.009801268577575684\n",
      "Epoch 1 Iter: 4500 Loss 0.05542159080505371\n",
      "Epoch 1 Iter: 5000 Loss 0.03602343797683716\n",
      "Epoch 1 Iter: 5500 Loss 0.007740974426269531\n",
      "Epoch 1 Iter: 6000 Loss 0.1637621521949768\n",
      "Epoch 1 Iter: 6500 Loss 0.0008903741836547852\n",
      "Epoch 1 Iter: 7000 Loss 0.004818558692932129\n",
      "Epoch 1 Iter: 7500 Loss 0.06691169738769531\n",
      "Epoch 1 Iter: 8000 Loss 0.0010306835174560547\n",
      "Epoch 1 Iter: 8500 Loss 0.002672433853149414\n",
      "Epoch 1 Iter: 9000 Loss 0.017661869525909424\n",
      "Epoch 1 Iter: 9500 Loss 2.5033950805664062e-05\n",
      "Epoch 1 Iter: 10000 Loss 0.013769865036010742\n",
      "Epoch 1 Iter: 10500 Loss 0.0025058984756469727\n",
      "Epoch 1 Iter: 11000 Loss 0.08055758476257324\n",
      "Epoch 1 Iter: 11500 Loss 0.051490843296051025\n",
      "Epoch 1 Iter: 12000 Loss 5.042552947998047e-05\n",
      "Epoch 1 Iter: 12500 Loss 0.47020018100738525\n",
      "Epoch 1 Iter: 13000 Loss 0.00245511531829834\n",
      "Epoch 1 Iter: 13500 Loss 0.14051032066345215\n",
      "Epoch 1 Iter: 14000 Loss 0.006453335285186768\n",
      "Epoch 1 Iter: 14500 Loss 0.01865246891975403\n",
      "Epoch 2 Iter: 0 Loss 0.0012974739074707031\n",
      "Epoch 2 Iter: 500 Loss 0.022809267044067383\n",
      "Epoch 2 Iter: 1000 Loss 0.2555362284183502\n",
      "Epoch 2 Iter: 1500 Loss 0.0005691051483154297\n",
      "Epoch 2 Iter: 2000 Loss 1.6739697456359863\n",
      "Epoch 2 Iter: 2500 Loss 0.0011223554611206055\n",
      "Epoch 2 Iter: 3000 Loss 0.017247498035430908\n",
      "Epoch 2 Iter: 3500 Loss 0.1893690824508667\n",
      "Epoch 2 Iter: 4000 Loss 0.20644605159759521\n",
      "Epoch 2 Iter: 4500 Loss 0.00014829635620117188\n",
      "Epoch 2 Iter: 5000 Loss 0.0031902194023132324\n",
      "Epoch 2 Iter: 5500 Loss 6.508827209472656e-05\n",
      "Epoch 2 Iter: 6000 Loss 0.00427478551864624\n",
      "Epoch 2 Iter: 6500 Loss 0.0032018423080444336\n",
      "Epoch 2 Iter: 7000 Loss 0.02210104465484619\n",
      "Epoch 2 Iter: 7500 Loss 0.00044596195220947266\n",
      "Epoch 2 Iter: 8000 Loss 0.04688990116119385\n",
      "Epoch 2 Iter: 8500 Loss 0.0019412040710449219\n",
      "Epoch 2 Iter: 9000 Loss 0.04879683256149292\n",
      "Epoch 2 Iter: 9500 Loss 0.004187583923339844\n",
      "Epoch 2 Iter: 10000 Loss 0.06578835844993591\n",
      "Epoch 2 Iter: 10500 Loss 0.008633971214294434\n",
      "Epoch 2 Iter: 11000 Loss 0.1966876983642578\n",
      "Epoch 2 Iter: 11500 Loss 0.001170039176940918\n",
      "Epoch 2 Iter: 12000 Loss 0.0003746151924133301\n",
      "Epoch 2 Iter: 12500 Loss 0.006283760070800781\n",
      "Epoch 2 Iter: 13000 Loss 0.0009174346923828125\n",
      "Epoch 2 Iter: 13500 Loss 0.5940966606140137\n",
      "Epoch 2 Iter: 14000 Loss 0.0009891986846923828\n",
      "Epoch 2 Iter: 14500 Loss 0.023622632026672363\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, criterion, trainloader, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12zEbgnwLBdg"
   },
   "source": [
    "Let's load a sample image from the test dataset, and see what the classifier makes of it. Make sure to visualize the image using `imshow(x[0,0])`. Also, note that the line `test_iter.next()` pulls a new input image from the test set each time you run it; try running the next code block a few times to get a sense of what the MNIST dataset looks like, and how the classifier performs on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFBwByD1LBdi"
   },
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "sB_m2TzpONdu",
    "outputId": "0f9bb58b-1662-4278-f220-865978e31d74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[-13.0860, -12.7495,  -6.1859,  -0.7290, -22.6499,  -7.4789, -36.9544,\n",
      "           7.4793, -10.2039,  -2.5041]], device='cuda:0')\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "x, labels = test_iter.next()\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6nekayzLygn"
   },
   "source": [
    "We can also measure the classifier's accuracy on the full test dataset. This function takes in a classifier we have trained and the loader for the test set, and outputs the classifier's accuracy. The accuracy is simply\n",
    "$$ \\dfrac{\\text{# correct}}{\\text{# total}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk4pq6hiLygr"
   },
   "outputs": [],
   "source": [
    "def accuracy(net, testloader):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET\n",
    "    on test data from TESTLOADER.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kXpxjHkqLBd8",
    "outputId": "fd398026-a318-4f65-b817-9893cb5a9287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on original test dataset: 0.9712\n"
     ]
    }
   ],
   "source": [
    "print('Classifier accuracy on original test dataset:', accuracy(net, testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrvBEzmZLBeD"
   },
   "source": [
    "## Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5ZlWjqILygz"
   },
   "source": [
    "Here, we implement the Fast Gradient Sign Method, which takes in a batch of input images, their labels, a trained classifier, and the epsilon radius within which the perturbation should lie. This function should output the input image perturbed in the direction of the sign of the gradient with respect to the classifier's loss.\n",
    "\n",
    "(Note that the output is not guaranteed to lie in the valid range for images, since here pixel values must be in $[-1,1]$. You should use `torch.clamp` to fix the FGSM output to lie in the correct range.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaSK1tjSLyg2"
   },
   "outputs": [],
   "source": [
    "def FGSM(x, labels, net, eps):\n",
    "    '''\n",
    "    Given an input image X and its corresponding labels\n",
    "    LABELS, as well as a classifier NET, returns X\n",
    "    perturbed by EPS using the fast gradient sign method.\n",
    "    '''\n",
    "    net.zero_grad()    # Zero out any gradients from before\n",
    "    x.requires_grad=True    # Keep track of gradients\n",
    "    out = net(x)    # Output of classifier\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(out, labels)   # Classifier's loss\n",
    "    loss.backward()\n",
    "    grads = x.grad.data    # Gradient of loss w/r/t input\n",
    "    x_next = torch.clamp(x + eps * torch.abs(grads), min = -1, max = 1)\n",
    "    return x_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB8K0vMsLBeU"
   },
   "source": [
    "Let's see how well the classifier does when the input is adversarially perturbed using FGSM. Try this for $\\varepsilon\\in\\{0.05, 0.1,0.2,0.3, 0.4\\}$, and again remember to visualize the inputs with `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhqJDeMS6T5m"
   },
   "outputs": [],
   "source": [
    "#eps =  # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dbS2KvG6Lyh6",
    "outputId": "80e3a1c7-e64b-4dab-aabd-dbfab98297a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "epsilon: 0.05\n",
      "Classifier output: tensor([[-13.0861, -12.7495,  -6.1858,  -0.7275, -22.6481,  -7.4780, -36.9536,\n",
      "           7.4780, -10.2011,  -2.5030]], device='cuda:0')\n",
      "Classifier prediction: 7\n",
      "0 20.564090728759766\n",
      "1 20.227432250976562\n",
      "2 13.663785934448242\n",
      "3 8.205513000488281\n",
      "4 30.126083374023438\n",
      "5 14.956001281738281\n",
      "6 44.43156814575195\n",
      "8 17.67905616760254\n",
      "9 9.980976104736328\n",
      "=================\n",
      "epsilon: 0.1\n",
      "Classifier output: tensor([[-13.0862, -12.7494,  -6.1857,  -0.7259, -22.6462,  -7.4771, -36.9527,\n",
      "           7.4765, -10.1980,  -2.5017]], device='cuda:0')\n",
      "Classifier prediction: 7\n",
      "0 20.562711715698242\n",
      "1 20.225910186767578\n",
      "2 13.662158966064453\n",
      "3 8.202377319335938\n",
      "4 30.12264633178711\n",
      "5 14.953545570373535\n",
      "6 44.42918014526367\n",
      "8 17.674474716186523\n",
      "9 9.9782133102417\n",
      "=================\n",
      "epsilon: 0.2\n",
      "Classifier output: tensor([[-13.0865, -12.7494,  -6.1854,  -0.7225, -22.6421,  -7.4751, -36.9508,\n",
      "           7.4733, -10.1915,  -2.4991]], device='cuda:0')\n",
      "Classifier prediction: 7\n",
      "0 20.559818267822266\n",
      "1 20.22270393371582\n",
      "2 13.658737182617188\n",
      "3 8.19577693939209\n",
      "4 30.115398406982422\n",
      "5 14.948369979858398\n",
      "6 44.42414093017578\n",
      "8 17.66482925415039\n",
      "9 9.97239875793457\n",
      "=================\n",
      "epsilon: 0.3\n",
      "Classifier output: tensor([[-13.0868, -12.7493,  -6.1851,  -0.7187, -22.6376,  -7.4728, -36.9487,\n",
      "           7.4699, -10.1844,  -2.4962]], device='cuda:0')\n",
      "Classifier prediction: 7\n",
      "0 20.55663299560547\n",
      "1 20.219175338745117\n",
      "2 13.654973983764648\n",
      "3 8.188516616821289\n",
      "4 30.107425689697266\n",
      "5 14.942681312561035\n",
      "6 44.41859436035156\n",
      "8 17.654218673706055\n",
      "9 9.966001510620117\n",
      "=================\n",
      "epsilon: 0.4\n",
      "Classifier output: tensor([[-13.0871, -12.7493,  -6.1848,  -0.7145, -22.6327,  -7.4704, -36.9465,\n",
      "           7.4661, -10.1766,  -2.4930]], device='cuda:0')\n",
      "Classifier prediction: 7\n",
      "0 20.55316162109375\n",
      "1 20.215328216552734\n",
      "2 13.65086841583252\n",
      "3 8.180598258972168\n",
      "4 30.098731994628906\n",
      "5 14.936477661132812\n",
      "6 44.41255569458008\n",
      "8 17.64264678955078\n",
      "9 9.959026336669922\n"
     ]
    }
   ],
   "source": [
    "# We are using the same sample input x as before.\n",
    "for eps in [0.05, 0.1, 0.2, 0.3, 0.4]:\n",
    "  x.requires_grad = True\n",
    "  x_prime = FGSM(x, labels, net, eps)\n",
    "  #imshow(x_prime[0,0].cpu())\n",
    "  out = net(x_prime)\n",
    "  print('=================')\n",
    "  print('epsilon: '+str(eps))\n",
    "  print('Classifier output:', out.data)\n",
    "  print('Classifier prediction:', torch.argmax(out).item())\n",
    "  for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, (out @ c).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64qakoWaLBec"
   },
   "source": [
    "We should evaluate the classifier's performance on FGSM-perturbed data by the same metric that we will later use in the primal adversarial problem. That is, for the classifier's output vector $\\vec{\\hat{z}}_3$, we want to compute\n",
    "$$\n",
    "\\vec{c}_j^\\top \\vec{\\hat{z}}_3\n",
    "$$\n",
    "where\n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "Recall that \n",
    "$$\\vec{c}_j^\\top \\vec{\\hat{z}}_3=\\vec{\\hat{z}}_{3i_{\\text{true}}}-\\vec{\\hat{z}}_{3j},$$\n",
    "i.e. $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is the difference between the classifier's confidence on the true class and the $j$th (incorrect) class. If $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is positive for all incorrect $j$, then the classifier was not fooled by the adversarial perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "qpFjSe3ULBee",
    "outputId": "c9ff44af-f55c-42b2-e0f9-41d48c4c534e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20.562423706054688\n",
      "1 20.2255859375\n",
      "2 13.66181755065918\n",
      "3 8.201717376708984\n",
      "4 30.12192153930664\n",
      "5 14.953027725219727\n",
      "6 44.428672790527344\n",
      "8 17.67350959777832\n",
      "9 9.977631568908691\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, (out @ c).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4JTyFqQLBeo"
   },
   "source": [
    "**Q: What do the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores tell you about the robustness of the classifier to different values of epsilon? For a given input digit, which output categories have higher/lower scores? Why?**\n",
    "\n",
    "A: The $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ score decreases with the value of epsilon increasing, which indicates that the robustness of the classifier to  a smaller epsilon value is better than that to a larger epsilon value.  \n",
    "Given the input digit is 7, 5 & 6 have higher scores and 2 & 9 have lower scores because 5 & 6 have features that are least similar to 7 and 2 & 9 have features that are most similar to 7. The larger the score is, the more confident the classifier is that the input digit is not of this output class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaGNmioNLyg_"
   },
   "source": [
    "Now that FGSM is defined, we can also measure a classifier's accuracy on a dataset where each input has been adversarially perturbed. That is, for each point in the original test dataset, we first perturb it using FGSM before feeding it to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ik9xXp3hLyhB"
   },
   "outputs": [],
   "source": [
    "def accuracy_on_FGSM(net, testloader, eps):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET on test\n",
    "    data from TESTLOADER that has been perturbed by\n",
    "    EPS using FSGM.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        x, labels = data[0].to(device), data[1].to(device)\n",
    "        x_prime = FGSM(x, labels, net, eps)\n",
    "        outputs = net(x_prime)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDD_z76ALBew"
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "x_plot = []\n",
    "y_plot = []\n",
    "for eps in np.array(range(0,31), dtype=float)/10:\n",
    "  #print('Classifier accuracy on test dataset perturbed with FGSM, eps is {} :'.format(str(eps)), accuracy_on_FGSM(net, testloader, eps))\n",
    "  cury = accuracy_on_FGSM(net, testloader, eps)\n",
    "  x_plot.append(eps)\n",
    "  y_plot.append(cury)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "Kk2zLvJCLPs3",
    "outputId": "b9765e80-9e0c-42ac-8f26-502ca9127c75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f68d50a44a8>]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('epsilon-accuracy')\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(x_plot,y_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dj-7r-oqLBe1"
   },
   "source": [
    "**Q: How does the classifier accuracy on data perturbed by FGSM compare to that on the original test dataset? How does this vary with epsilon?**\n",
    "\n",
    "A: It is plotted above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDwEDxf9LBe7"
   },
   "source": [
    "## Dual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkVG-qEuLyhK"
   },
   "source": [
    "Here, we will implement the dual network. First, we write the function to compute upper and lower bounds for the dual network. This function should take an input image, the trained classifier, and an epsilon value, and return the tuple\n",
    "$$(\\vec{l},\\vec{u},S,S^-,S^+)$$\n",
    "where $\\vec{u}$ and $\\vec{l}$ are the upper and lower bounds, respectively, for the input to the ReLU layer, and $S^-,S^+,S$ are sets defined by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&S:=\\{j\\in [n_2]\\mid l_{j}\\leq 0\\leq u_{j}\\}\\\\\n",
    "&S^{-}:=\\{j\\in [n_2]\\mid l_{j}\\leq u_{j}\\leq 0\\}\\\\\n",
    "&S^{+}:=\\{j\\in [n_2]\\mid 0\\leq l_{j}\\leq u_{j}\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "See Section 6 of the PDF for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0QHBHTHLyhO"
   },
   "outputs": [],
   "source": [
    "def dual_bounds(x, net, eps):\n",
    "    '''\n",
    "    Given a classifier NET, an input image X,\n",
    "    and the epsilon parameter EPS, returns the lower\n",
    "    and upper bounds L and U respectively, as well as\n",
    "    the corresponding sets S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = torch.tensor(x[0].reshape(-1, 1)).to(device)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "    b0 = b[0].to(device)\n",
    "    W0 = W[0].to(device)\n",
    "    factor = torch.norm(W[0],p=1,dim=1).reshape(-1,1)\n",
    "    #print(factor.shape)\n",
    "    u = W[0].mm(x) + b[0]+eps *factor\n",
    "    l = W[0].mm(x) + b[0] - eps *factor\n",
    "    \n",
    "    S = ((u>=0) & (l<=0)).clone().detach()\n",
    "    S_plus = (l>=0).clone().detach()\n",
    "    S_min = (u<=0).clone().detach()\n",
    "    return l, u, S, S_min, S_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaMhcqTvLyhX"
   },
   "source": [
    "Given the tuple $(l,u,S,S^-,S^+)$, we are ready to calculate the dual objective itself. This function should take in an input image, the classifier, a vector $c$, and the $(l,u,S,S^-,S^+)$ from the previous function in order to output \n",
    "$$\n",
    "d^*(\\vec{x},\\vec{c})= \n",
    "-\\vec{\\hat{\\nu}}_1^\\top \\vec{x}-\\varepsilon\\|\\vec{\\hat{\\nu}}_1\\|_1-\\sum_{i=1}^{2}\\vec{\\nu}_{i+1}^\\top \\vec{b}_i+\\sum_{j\\in S\\\n",
    "}l_{j}\\text{ReLU}(\\nu_{2j})\n",
    "$$\n",
    "\n",
    "Where the $\\vec{\\nu}$ vectors are computed as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\vec{\\nu}_3=-\\vec{c}\\\\\n",
    "&\\vec{\\hat{\\nu}}_2=W_2^\\top \\vec{\\nu}_{3}\\\\\n",
    "&\\nu_{2j}=0 && \\forall j\\in S^-\\\\\n",
    "&\\nu_{2j}=\\hat{\\nu}_{2j} && \\forall j\\in S^+\\\\\n",
    "&\\nu_{2j}=\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} && \\forall j\\in S\\\\\n",
    "&\\vec{\\hat{\\nu}}_1=W_1^\\top \\vec{\\nu_{2}}\n",
    "&\\end{aligned}.\n",
    "$$\n",
    "\n",
    "Again, see Section 6 of the PDF for more details.\n",
    "\n",
    "One efficient way to compute $\\vec{\\nu}_2$ is to rewrite it as\n",
    "$$\\vec{\\nu}_2= D\\vec{\\hat{\\nu}}_2,$$\n",
    "where $D$ is a diagonal matrix defined  by\n",
    "$$\n",
    "D_{jj}=\\begin{cases}\n",
    "0 & j\\in S^-\\\\\n",
    "\\hat{\\nu}_{2j} & j\\in S^+\\\\\n",
    "\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} & j\\in S.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chl5lue0Lyha"
   },
   "outputs": [],
   "source": [
    "# Constructs the diagonal D matrix from the S sets, n (the dimensionality\n",
    "# of the hidden layer), u, and l.\n",
    "def StoD(S_min, S_plus, S, n, u, l):\n",
    "    '''\n",
    "    Given upper and lower bounds U and L, as well\n",
    "    as the corresponding sets S_MIN, S_PLUS, and S,\n",
    "    as well as the dimension of the hidden layer N,\n",
    "    returns the corresponding diagonal matrix D.\n",
    "    '''\n",
    "    d = []\n",
    "    for j in range(n):\n",
    "        if S[j] and not (S_min[j] or S_plus[j]):\n",
    "            d.append((u[j] / (u[j] - l[j])).item())\n",
    "        elif S_plus[j] and not (S[j] or S_min[j]):\n",
    "            d.append(1)\n",
    "        elif S_min[j] and not (S[j] or S_plus[j]):\n",
    "            d.append(0)\n",
    "        else:\n",
    "            assert False, 'StoD error.'\n",
    "    return torch.diag(torch.Tensor(d)).to(device)\n",
    "\n",
    "def dual_forward(x, net, c, eps, l, u, S, S_min, S_plus):\n",
    "    '''\n",
    "    Calculates the dual objective for classifier NET with input X\n",
    "    and dual input C and epsilon parameter S. Depends on lower\n",
    "    and upper bounds L and U, as well as the corresponding sets\n",
    "    S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = x[0].reshape(-1, 1)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "    D = StoD(S_min, S_plus, S, n, u, l)\n",
    "    # TODO: Your code here!\n",
    "    v3 = -1 * c.to(device)\n",
    "    v2_hat = torch.transpose(W[1],0,1).to(device).mm(v3).to(device)\n",
    "    #print(v2_hat)\n",
    "    v2 = D.mm(v2_hat).to(device)\n",
    "    v1_hat = torch.transpose(W[0],0,1).to(device).mm(v2).to(device)\n",
    "    d_star = -1 * torch.transpose(v1_hat,0,1).mm(x).to(device)\n",
    "    # print(torch.norm(v1_hat, 1, 0).shape)\n",
    "    # print('pre'+str(d_star.shape))\n",
    "    # print('norm'+str(torch.norm(v1_hat, 1, 0).shape))\n",
    "    d_star = d_star - eps * (torch.norm(v1_hat, 1, 1)[0])\n",
    "    # print(d_star.shape)\n",
    "    d_star = d_star - torch.transpose(v2, 0, 1).mm(b[0].to(device)) - torch.transpose(v3, 0, 1).mm(b[1].to(device))\n",
    "    # print(d_star.shape)\n",
    "    v2_reshape = v2[S].reshape(-1,1).to(device)\n",
    "    v2_relu = torch.where(v2_reshape<0, torch.zeros(v2_reshape.shape).to(device), v2_reshape).to(device)\n",
    "    d_star = d_star + l[S].reshape(1,-1).mm(v2_relu)\n",
    "    #print(l[S].reshape(1,-1).mm(v2_relu))\n",
    "    #print(torch.sum(l[S]))\n",
    "    # print('dstar '+str(d_star.shape))\n",
    "\n",
    "    return d_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HagySRiNLyhu"
   },
   "source": [
    "Now, we can use the dual network to check the robustness of the network we just trained on sample input images. We can do this for \n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "The output is a vector where the $j$th element is the difference between the model's confidence in the true class and the $j$th class; if $d^*(\\vec{x},\\vec{c}_j)$ is nonnegative for every $j\\in[10]$, then we know the model is robust to perturbations of size $\\varepsilon$. See Section 8 of the PDF for more details.\n",
    "\n",
    "Try running the following block of code for different values of $\\varepsilon\\in\\{0.05, 0.1, 0.2, 0.3, 0.4\\}$, and compare the robustness guarantees here with the classifier's performance on the FGSM data from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMzFyrOr6T53"
   },
   "outputs": [],
   "source": [
    "eps = 0.05 # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WY6TfL2GLyhw",
    "outputId": "27bf0d02-5926-4b7a-bd51-b84aa9303e46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0 19.53915786743164 20.56372833251953\n",
      "1 19.347139358520508 20.227033615112305\n",
      "2 12.508111953735352 13.663359642028809\n",
      "3 7.082707405090332 8.204689025878906\n",
      "4 28.81760597229004 30.12518310546875\n",
      "5 13.947456359863281 14.955357551574707\n",
      "6 43.09099578857422 44.43094253540039\n",
      "8 16.27264976501465 17.677852630615234\n",
      "9 8.88763427734375 9.980249404907227\n",
      "===============\n",
      "0.1\n",
      "0 16.215076446533203 20.563655853271484\n",
      "1 16.082265853881836 20.226951599121094\n",
      "2 9.771034240722656 13.663272857666016\n",
      "3 3.394176483154297 8.204524040222168\n",
      "4 24.488967895507812 30.124998092651367\n",
      "5 9.768722534179688 14.955225944519043\n",
      "6 39.670955657958984 44.430816650390625\n",
      "8 11.86845874786377 17.677610397338867\n",
      "9 4.873041152954102 9.980103492736816\n",
      "===============\n",
      "0.2\n",
      "0 1.580510139465332 20.563581466674805\n",
      "1 4.184932708740234 20.22687339782715\n",
      "2 -3.022064208984375 13.663187026977539\n",
      "3 -11.380857467651367 8.204357147216797\n",
      "4 8.692623138427734 30.124818801879883\n",
      "5 -7.031081199645996 14.955095291137695\n",
      "6 23.61827850341797 44.43069076538086\n",
      "8 -3.647027015686035 17.6773681640625\n",
      "9 -10.130411148071289 9.979957580566406\n",
      "===============\n",
      "0.3\n",
      "0 -18.1629638671875 20.56351089477539\n",
      "1 -14.541738510131836 20.226789474487305\n",
      "2 -22.909034729003906 13.663101196289062\n",
      "3 -32.05162811279297 8.204193115234375\n",
      "4 -14.3287353515625 30.124635696411133\n",
      "5 -28.885379791259766 14.95496654510498\n",
      "6 -1.6692161560058594 44.430564880371094\n",
      "8 -22.98923110961914 17.677125930786133\n",
      "9 -30.045822143554688 9.979812622070312\n",
      "===============\n",
      "0.4\n",
      "0 -36.52280807495117 20.563438415527344\n",
      "1 -33.67796325683594 20.226709365844727\n",
      "2 -43.184146881103516 13.663015365600586\n",
      "3 -52.25334548950195 8.204028129577637\n",
      "4 -36.942501068115234 30.124452590942383\n",
      "5 -51.369293212890625 14.95483684539795\n",
      "6 -26.28948211669922 44.4304313659668\n",
      "8 -42.08064651489258 17.676883697509766\n",
      "9 -49.66987991333008 9.979665756225586\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dual_estimate(eps):\n",
    "  # We are still using the same sample input x as before.\n",
    "  l, u, S, S_min, S_plus = dual_bounds(x, net, eps)\n",
    "\n",
    "  # Here, we loop through each column c_j defined above, and output the \n",
    "\n",
    "  # objective value for the dual function with input c.\n",
    "  for i in range(10):\n",
    "      c = torch.zeros(10, 1).to(device)\n",
    "      if i != labels:\n",
    "          c[i] = -1\n",
    "          c[labels] = 1\n",
    "          print(i, dual_forward(x, net, c, 0.1, l, u, S, S_min, S_plus).item(), (out@c).item())\n",
    "\n",
    "for e in [0.05, 0.1, 0.2, 0.3, 0.4]:\n",
    "  print(e)\n",
    "  x.requires_grad = True\n",
    "  x_prime = FGSM(x, labels, net, eps)\n",
    "  #imshow(x_prime[0,0].cpu())\n",
    "  out = net(x_prime)\n",
    "  dual_estimate(e)\n",
    "  print('===============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v--Zs9ELLyiB"
   },
   "source": [
    "**Q: What do the dual network outputs tell you about the robustness of the classifier? How does this compare to the classifier's performance (in particular, the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores) on FGSM outputs? How does your answer change with epsilon?**\n",
    "\n",
    "A: The dual outputs show that the robustness of the classifier is very bad. With a small perturbation, the confidence difference would be negative with a large magnitude. Compared with the FGSM outputs, the classifier is much more sensitive to perturbations. The larger epsilon is, the more negative(negative number with larger maginitude) the values are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dr3xSI7EMv4l"
   },
   "source": [
    "**Q: Suppose you have a deep neural classifier that you want to defend against adversarial attacks. That is, you want to detect and discard any input images that were possibly adversarially perturbed. How might you do this with the robustness certificate you have implemented?**\n",
    "\n",
    "A: Using $c_j$ generated by all the classes that are different from the label to compute $d^*(\\vec{x}, \\vec{c_j})$. If the value is positive for all the classes, then there's no perturbation within the magnitude of $\\epsilon$ that can fool the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s--Ae8VpLyiN"
   },
   "source": [
    "## Optional: Robust training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LohSkAUMLBfa"
   },
   "source": [
    "The following function should implement the robust loss from section A of the PDF. This loss is an upper bound on the worst-case loss within an $\\epsilon$ ball of the original training input. Thus, training using this new loss should result in a classifier that is more robust than one trained on the original cross-entropy loss.\n",
    "\n",
    "There are no mandatory questions here, but feel free to experiment with this robust training, and compare the performance here (measured by the dual objective certificate, as well as original/FGSM accuracy) to that of the original. You can also try training a model using the original loss first, then fine-tuning with the robust loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTv9zjuqLyiQ"
   },
   "outputs": [],
   "source": [
    "def robust_loss(x, label, net, eps, criterion):\n",
    "    '''\n",
    "    Given a batch of input images X, its corresponding lables LABEL,\n",
    "    the classifier NET, epsilon value EPS, and original loss\n",
    "    function CRITERION, returns the robust loss of NET w/r/t\n",
    "    the original loss function, on the input image.\n",
    "    '''\n",
    "    l, u, S, S_min, S_plus = dual_bounds(x.to(device), net, eps)\n",
    "    # We assume there are 10 classes.\n",
    "    e_y = torch.zeros(10, 1)\n",
    "    e_y[label] = 1\n",
    "    c = e_y @ torch.ones(1, 10) - torch.eye(10)\n",
    "    J = dual_forward(x, net, c, eps, l, u, S, S_min, S_plus).unsqueeze(0)\n",
    "    return criterion(-J, label.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj_VkNaNLyiY"
   },
   "outputs": [],
   "source": [
    "def robust_train(net, criterion, trainloader, eps, lr=0.001):\n",
    "    '''\n",
    "    Trains the classifier NET using the robust version\n",
    "    of the original loss function CRITERION with paramater EPS,\n",
    "    using training data from TRAINLOADER and with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for i in range(inputs.shape[0]):\n",
    "                x = inputs[i].unsqueeze(0).to(device)\n",
    "                label = labels[i].unsqueeze(0)\n",
    "                loss += robust_loss(x, label, net, eps, criterion)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gIlu7953L0B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "adversarial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
